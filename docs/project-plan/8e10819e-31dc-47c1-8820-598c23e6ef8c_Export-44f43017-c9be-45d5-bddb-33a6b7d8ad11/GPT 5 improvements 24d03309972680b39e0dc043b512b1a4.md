# GPT 5 improvements

# Upgrades that matter

## 1) Contract-level provenance contract (mandatory)

Every field/claim must carry:

- `doc_id`, `doc_sha256`, `doc_version`
- `page`, `bbox[]` (or char offsets) **and** the exact `snippet`
- `extractor`: `rule|model|human`, plus `confidence`
- `derived_from`: array of other field IDs when you compute a value (e.g., “Total = Sum(rows)”)
- `timestamp` + `agent_id`
    
    This becomes your ground truth for both UI highlighting and audit logs.
    

## 2) Conflict engine (amendments vs originals)

When multiple instruments assert the same attribute:

- Define a **precedence graph** (e.g., Amendment N overrides N-1; Estoppel overrides prior estoppels only on certain terms).
- The DB should store **both** the chosen value and the **losing candidates** with reasons: `superseded_by`, `conflict_rule_applied`.
- UI: “Why this value?” → show a mini timeline with the highlighted spans from the original + amendments and the rule that chose the winner.

## 3) Table cell anchoring (not just page bbox)

- Store **cell-level polygons** (row, col, bbox) for all financial tables.
- Every number in an answer that came from a table must point to a **cell id** (not just a generic page region).
- Validator: sum checks, currency/percent typing, and row/col header sanity.

## 4) Review Queue that scales

- Priority = `criticality * (1 - confidence) * impact` (you define impact by term type: e.g., price/date > boilerplate).
- Batch similar issues (same template, same clause) into one task to avoid death-by-a-thousand-clicks.
- Auto-close tasks if downstream amendments make them irrelevant (tie into the conflict engine).

## 5) UI refinements (fast and lawyer-proof)

- **Evidence pane everywhere**: per-field chips → click → jump to page, show overlay highlights (PDF.js + overlay).
- **Clause diff viewer**: original vs amendment side-by-side; color A/B highlights.
- **Map view**: parcel click → list all instruments touching it; filter by encumbrance type; each item jumps to highlighted span.
- **One-click “promote human fix”**: human correction becomes a first-class datum with its own citation (the document/images they used).

## 6) Routing refinements (cut wasted cycles)

- Before OCR, run a **text-layer sniff** (pdfminer/pymupdf). If >95% text present, skip OCR; still store page images for highlighting.
- Record **image quality metrics** (dpi estimate, skew, contrast). If below thresholds → shove straight to HIL without burning GPU hours.
- Timeouts/backpressure: if a stage stalls, fail fast and queue HIL with the reason (keeps the pipeline moving).

## 7) Accuracy guarantees (make “100%” real)

Adopt gating rules; don’t ship answers unless:

- Every field has **at least one** verified span (exact or numerically equivalent after parsing).
- For computed values (totals), the underlying components also have spans and passed checksum rules.
- For conflicts, a **precedence rule** is recorded and rendered to the user on request.
- Anything failing gates is blocked behind HIL.

## 8) Versioning & immutability

- **Immutable document blobs** keyed by `sha256`; never overwrite.
- `doc_version` rows track replacements (re-scan, certified copy). Keep lineage.
- Provenance records **must** store the exact `sha256` they read from. If the file is replaced, previous extractions do **not** auto-repoint.

## 9) Learning loop (safe)

- Never overwrite the raw field; add a **new extractor version** and mark the older one as superseded.
- Only learn from HIL when: same template class, same clause label, and the human result validated against a span.
- Keep a frozen **gold set** (50–100 docs) and run regression before enabling a new extractor in prod.

# Phase-by-phase tweaks

## Phase 1 (MVP)

- Add the **provenance contract** to the API now.
- Implement **page image + highlight overlay** and **record→document jump**.
- Basic HIL form: transcribe / upload / ignore; every action produces a new provenance record (`extractor: "human"`).

## Phase 2 (Advanced HIL & Linking)

- Ship the **conflict engine** + clause diff viewer.
- Inter-document links: `(Instrument)-[:AMENDS]->(Instrument)`, `(Instrument)-[:ENCUMBERS]->(Parcel)`, `(Table)-[:OF]->(Instrument)`.
- OCR word/line map so clicking text in the right pane jumps to the exact glyph region (not just rough bbox).

## Phase 3 (Automation & Learning)

- Prioritized **Review Queue** with batching and SLA tags.
- Online **rules promotion**: when a human corrects a recurring pattern, generate a candidate rule and stage it; require regression pass before auto-enable.
- Auto-trigger downstream workflows **only** when gate checks pass and no open conflicts remain.

# Data model adds (small but key)

- `Extraction`: `{ field_id, value, doc_sha256, page, bbox, snippet, extractor, confidence, created_at }`
- `Conflict`: `{ field_name, candidates[], chosen_id, rule_id, reasoning }`
- `TableCell`: `{ cell_id, doc_sha256, page, bbox, row, col, header_paths[] }`
- `HumanReviewTask`: `{ task_id, reason, doc_sha256, page, bbox, priority, status }`

# Tech picks (keep it simple)

- **Viewer**: PDF.js + canvas overlay (client), PyMuPDF for server-side thumbnails.
- **Storage**: Neo4j (relations/conflicts), Postgres (extractions, tasks), S3/MinIO (blobs), Qdrant (semantic).
- **Validator**: tiny Python service using PyMuPDF to re-pull text within bbox; `money/date` normalizers; table checksum.

# Acceptance checks you can enforce

- 100% of shipped fields have `doc_sha256 + page + bbox + snippet`.
- 0 computed fields without resolvable components.
- All conflicts show a precedence rule in the UI within one click.
- Random 1% sampling goes to HIL even if high confidence (keeps you honest).

---

Bottom line: your plan is right-sized. Add the conflict engine, table cell anchoring, strict provenance fields, and hard gates. That’s how you get “lawyer-grade” accuracy without choking your pipeline. If you want, I can sketch the Postgres tables + a tiny validator API to bolt onto your stack so the UI highlights “just work.”

[](Untitled%2024d033099726809ea3e5d23bdfdb163c.md)