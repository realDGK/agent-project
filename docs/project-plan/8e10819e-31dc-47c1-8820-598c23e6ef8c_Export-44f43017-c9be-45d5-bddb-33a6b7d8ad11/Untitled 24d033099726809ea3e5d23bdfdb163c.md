# Untitled

# What to lock in now (non-negotiables)

- **Receipts in every answer**: page, bbox/char offsets, snippet, doc SHA-256, extractor (`rule|model|human`), confidence. No provenance = no answer.
- **Conflict resolution**: amendments vs originals, estoppels, notices. Always store *all* candidates + the rule that chose the winner. Show the timeline + highlighted spans on click.
- **Table cell anchoring**: every dollar/date that comes from a table must point to a **cell id** (row/col + bbox). Run checksum/typing (money/%/date) before you let it through.

# Biggest risks (and how to eliminate them)

1. **Email is your only ground truth.**
    - Do **two pipelines**: (a) **Graph API incremental sync** for live mailbox; (b) **PST ingestion** (libpff/pypff) for historical dumps.
    - Preserve **headers**, **Message-ID**, **In-Reply-To/References**, DKIM/Received chain where present. Hash the **raw MIME**.
    - **Attachment de-dup** by content hash; track each attachment’s first seen message + all re-forwards (chain of custody).
    - Build **Thread → Deal** clustering with: subject normalization, quoted-text strip, NER (project names, addresses, APNs), and a fuzzy alias book (“Ramona Chace” == “RC”, etc.).
2. **Amendments obliterating context.**
    - Precedence graph: `ORIGINAL <- AMEND_1 <- AMEND_2 …` with clause-level override map.
    - UI: “Why this value?” → side-by-side clause diff (original vs amendment), both spans highlighted.
3. **Financial tables** (rent schedules, draw ledgers) getting mangled.
    - Prefer structured extract (pdfplumber/tabula → Camelot lattice) + **cell polygons** stored.
    - **Validator**: totals match? columns typed? dates monotonic? If fail → HIL.
4. **Maps & parcel references.**
    - Add **PostGIS**. Store parcel geometries + cross-refs by APN; index docs by parcel.
    - Parcel click ⇒ list of instruments touching it, each with page jump + highlights.

# Architecture tweaks (keep it lean)

- **Stick with Postgres as primary truth**, but:
    - Enable **PostGIS** (parcels) and **pgvector** (semantic recall).
    - Use JSONB for extraction payloads + provenance; strict tables for parties, instruments, obligations, parcels, tables, conflicts, reviews.
    - If you later need complex path queries, *consider* Neo4j—but don’t prematurely split your store.
- **Add a queue** (RQ/Celery/Arq) behind the Agent API. Goose asks; workers do the long work. Idempotency tokens on every job.
- **Model mix**: keep **LegalBERT + spaCy rules** for precision; use **Gemini** only to *label* spans and summarize *with citations*. Never let a model “invent” text—every field must pass your validator against the cited span.

# Minimal schema (Postgres, trimmed)

- `document(doc_id, sha256, filename, source, mime, dkim_ok, received_at, created_at)`
- `email(message_id, thread_id, from, to, cc, subject_norm, sent_at, raw_sha256, doc_id_fk)`
- `attachment(att_id, sha256, filename, mime, first_message_id, doc_id_fk)`
- `instrument(id, doc_id, type, recorded_on, recording_ref)`
- `party(id, name)` + `instrument_party(instrument_id, party_id, role, page, bbox, extractor, confidence)`
- `obligation(id, instrument_id, kind, amount, due, applies_to_parcel, page, bbox, extractor, confidence)`
- `table_cell(id, instrument_id, page, row, col, bbox, header_path)`
- `extraction(field_id, instrument_id, name, value, page, bbox, snippet, extractor, confidence, created_at)`
- `conflict(field_name, instrument_scope, chosen_field_id, rule_id, reasoning)` + `conflict_candidate(conflict_id, field_id)`
- `review_task(id, reason, doc_id, page, bbox, priority, status, created_at)`
- `parcel(apn, geom, county)` + `instrument_parcel(instrument_id, apn, relation)`

# Pipeline (right-sized for you)

**Lane A (fast path)**

PST/Graph → normalize → OCR if needed → partition (Docling/Unstructured) → quick heuristics (doc type, parties, key dates/$$) → write elements + previews + provenance → **Agent graph** consumes.

**Lane B (only on trouble)**

Trigger if OCR/partition score low, table density high, or validator fails → MMOCR line maps, Camelot lattice, clause span tagging, HIL task creation.

**Gates** (no exceptions):

- Every shipped field has `sha256+page+bbox+snippet` and **passes validator** parity with the span.
- Computed values trace to components with spans.
- Conflicts resolved with a recorded rule.

# UI: unify answers + HIL (you’re close)

- **Evidence panel under every field**: chips per source page; click → PDF.js canvas with overlay highlights; hover → snippet.
- **Clause diff viewer** for amendments.
- **Review console** is the same viewer, but editable: transcribe / upload better scan / “ignore (boilerplate)”. Actions write **new extraction rows** with `extractor='human'` and their own citations.

# Email-first discovery (you’ll need this ASAP)

- **Deal discovery**: cluster threads by project tokens (NER hits for addresses/APNs/org names) + shared attachments.
- **Timeline** per deal: instruments, notices, payments, milestones. Status derived from obligations (open/closed/at-risk) with dates pulled from spans.
- **People map**: who corresponds about which deal; surface the power users + external counsel automatically.

# Commercialization checkboxes (so you can sell it)

- **Multi-tenant**: row-level security; tenant_id on *every* table; S3 prefixes per tenant.
- **Audit**: every view/download, every evidence click.
- **Retention**: per-tenant policies (legal holds).
- **Redaction**: Presidio pass on exports; keep original immutable.
- **Deployment**: split control plane (auth/billing) from data plane (tenant workloads).
- **“No provenance, no answer”** policy baked into the API—your moat.

# 30-day plan (aggressive but doable)

**Week 1**

- Wire Graph + PST ingest, raw MIME storage, attachment hashing, basic thread clustering.
- Add PostGIS + pgvector.
- Lane A OCR/partition + previews + element JSON (with page/bbox).

**Week 2**

- Extraction v1: parties/dates/$$ rules + validator.
- Evidence panel (PDF.js + overlays).
- Conflict model (store candidates, pick winner by rule).

**Week 3**

- Tables: Camelot lattice + cell polygons + checksum validator.
- Amendment diff viewer.
- Review queue MVP (priority = impact × (1–confidence)).

**Week 4**

- Deal timelines + parcel map view.
- Sampling QA (1% random to HIL), metrics dashboard (field-level F1, coverage, review backlog).
- Hard gates on API (block un-cited fields).

---

Blunt truth: your current plan is good, but without **conflict handling, table cell anchors, and ruthless provenance gates**, you won’t hit “100% accurate” in practice. Add those three, plus PostGIS/pgvector, and you’ve got a system that can digest your partner’s inbox, rebuild every deal with receipts, and be sellable to any RE shop that’s tired of guessing. If you want, I’ll sketch the exact Postgres DDL and a tiny validator endpoint next.